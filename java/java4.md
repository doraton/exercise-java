# 并发

共计37题

### Q1: JMM的作用是什么?

Java线程的通信由JMM控制，JMM的主要目的是定义程序中各种变量的访问规则。变量包括实例字
段、静态字段，但不包括局部变量与方法参数，因为它们是线程私有的，不存在多线程竞争。JMM遵循
一个基本原则:只要不改变程序执行结果，编译器和处理器怎么优化都行。例如编译器分析某个锁只会
单线程访问就消除锁，某个volatile变量只会单线程访问就把它当作普通变量。
JMM规定所有变量都存储在主内存，每条线程有自己的工作内存，工作内存中保存被该线程使用的变量
的主内存副本，线程对变量的所有操作都必须在工作空间进行，不能直接读写主内存数据。不同线程间
无法直接访问对方工作内存中的变量，线程通信必须经过主内存。
关于主内存与工作内存的交互，即变量如何从主内存拷贝到工作内存、从工作内存同步回主内存，JMM
定义了8种原子操作:

### Q2: as-if-serial 是什么?

不管怎么重排序，单线程程序的执行结果不能改变，编译器和处理器必须遵循as-if-serial 语义。
为了遵循as-if-serial,编译器和处理器不会对存在数据依赖关系的操作重排序，因为这种重排序会改变
执行结果。但是如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。
as-if-serial把单线程程序保护起来，给程序员-种幻觉:单线程程序是按程序的顺序执行的。



### Q3: happens-before 是什么?

先行发生原则，JMM定义的两项操作间的偏序关系，是判断数据是否存在竞争的重要手段。
JMM将happens-before要求禁止的重排序按是否会改变程序执行结果分为两类。对于会改变结果的重
排序JMM要求编译器和处理器必须禁止，对于不会改变结果的重排序, JMM不做要求。
JMM存在一些天然的 happens-before关系，无需任何同步器协助就已经存在。如果两个操作的关系不
在此列，并且无法从这些规则推导出来，它们就没有顺序性保障，虚拟机可以对它们随意进行重排序。
●程序次序规则: -个线程内写在前面的操作先行发生于后面的。
●管程锁定规则: unlock 操作先行发生于后面对同一个锁的lock操作。
●volatile 规则:对volatile变量的写操作先行发生于后面的读操作。
●线程启动规则:线程的start方法先行发生于线程的每个动作。
●线程终止规则:线程中所有操作先行发生于对线程的终止检测。
●对象终结规则:对象的初始化先行发生于finalize方法。
●传递性:如果操作A先行发生于操作B,操作B先行发生于操作C,那么操作A先行发生于操作
C。



### Q4: as-if-serial 和happens-before有什么区别?

as-if-serial保证单线程程序的执行结果不变，happens-before 保证正确同步的多线程程序的执行结果
不变。
这两种语义的目的都是为了在不改变程序执行结果的前提下尽可能提高程序执行并行度。



### Q5:什么是指令重排序?

为了提高性能，编译器和处理器通常会对指令进行重排序，重排序指从源代码到指令序列的重排序，分
为三种:①编译器优化的重排序，编译器在不改变单线程程序语义的前提下可以重排语句的执行顺序。
②指令级并行的重排序，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。③
内存系统的重排序。



### Q6:原子性、可见性、有序性分别是什么?

原子性
基本数据类型的访问都具备原子性，例外就是long和double,虚拟机将没有被volatile修饰的64位
数据操作划分为两次32位操作。
如果应用场景需要更大范围的原子性保证，JMM还提供了lock和unlock操作满足需求，尽管JVM没
有把这两种操作直接开放给用户使用，但是提供了更高层次的字节码指令monitorenter和
monitorexit，这两个字节码指令反映到Java代码中就是synchronized。
可见性
可见性指当一个线程修改了共享变量时，其他线程能够立即得知修改。JMM通过在变量修改后将值同步
回主内存，在变量读取前从主内存刷新的方式实现可见性，无论普通变量还是volatile变量都是如此,
区别是volatile保证新值能立即同步到主内存以及每次使用前立即从主内存刷新。
除了volatile外，synchronized 和final也可以保证可见性。同步块可见性由"对一个变量执行unlock
前必须先把此变量同步回主内存，即先执行store和write' '这条规则获得。final 的可见性指:被final
修饰的字段在构造方法中一旦初始化完成，并且构造方法没有把this引用传递出去，那么其他线程就能
看到final字段的值。
有序性
有序性可以总结为:在本线程内观察所有操作是有序的，在-个线程内观察另一个线程，所有操作都是
无序的。前半句指as-if-serial语义，后半句指指令重排序和工作内存与主内存延迟现象。
Java提供volatile和synchronized保证有序性, volatile 本身就包含禁止指令重排序的语义，而
synchronized保证一个变量在同一时刻只允许一条线程对其进行 lock操作，确保持有同一个锁的两个
同步块只能串行进入。

### Q7:谈一谈volatile

JMM为volatile定义了一些特殊访问规则，当变量被定义为volatile 后具备两种特性:
●保证变量对所有线程可见
当-条线程修改了变量值，新值对于其他线程来说是立即可以得知的。volatile 变量在各个线程的
工作内存中不存在-致性问题，但Java的运算操作符并非原子操作，导致volatile变量运算在并
发下仍不安全。
●禁止指令重排序优化
使用volatile变量进行写操作，汇编指令带有lock前缀,相当于一个内存屏障，后面的指令不能
重排到内存屏障之前。
使用lock前缀引发两件事:①将当前处理器缓存行的数据写回系统内存。②使其他处理器的缓存
无效。相当于对缓存变量做了- -次store和write操作,让volatile变量的修改对其他处理器立即
可见。
静态变量i执行多线程i++的不安全问题
自增语句由4条字节码指令构成的，依次为getstatic、 iconst_ 1、iadd、 putstatic, 当
getstatic把i的值取到操作栈顶时，volatile 保证了i值在此刻正确，但在执行iconst_ 1、iadd
时，其他线程可能已经改变了i值，操作栈顶的值就变成了过期数据,所以putstatic 执行后就可能
把较小的i值同步回了主内存。

适用场景
①运算结果并不依赖变量的当前值。②-写多读,只有单一的线程修改变量值。
内存语义
写一个volatile变量时，把该线程工作内存中的值刷新到主内存。
读一个volatile变量时，把该线程工作内存值置为无效，从主内存读取。
指令重排序特点
第二个操作是volatile写，不管第一个操作是什么都不能重排序，确保写之前的操作不会被重排序到写
之后。
第一个操作是volatile读，不管第二个操作是什么都不能重排序，确保读之后的操作不会被重排序到读
之前。.
第一个操作是volatile写,第二个操作是volatile读不能重排序。
JSR-133增强volatile语义的原因
在旧的内存模型中，虽然不允许volatile变量间重排序,但允许volatile变量与普通变量重排序，可能
导致内存不可见问题。JSR-133 严格限制编译器和处理器对volatile变量与普通变量的重排序，确保
volatile的写读和锁的释放获取具有相同的内存语义。



### Q8: final 可以保证可见性吗?

final可以保证可见性，被final修饰的字段在构造方法中一旦被初始化完成，并且构造方法没有把this
引用传递出去，在其他线程中就能看见final字段值。
在旧的JMM中,一个严重缺陷是线程可能看到final值改变。比如一个线程看到一个int类型final值
为0，此时该值是未初始化前的零值，一段时间后该值被某线程初始化，再去读这个final值会发现值变
为1。
为修复该漏洞，JSR-133 为final域增加重排序规则:只要对象是正确构造的(被构造对象的引用在构造
方法中没有逸出)，那么不需要使用同步就可以保证任意线程都能看到这个final 域初始化后的值。
写final域重排序规则
禁止把final域的写重排序到构造方法之外，编译器会在final域的写后，构造方法的return前，插入
一个Store Store屏障。确保在对象引用为任意线程可见之前，对象的final 域已经初始化过。
读final域重排序规则
在一个线程中，初次读对象引用和初次读该对象包含的final域，JMM 禁止处理器重排序这两个操作。
编译器在读final域操作的前面插入一个Load Load屏障,确保在读一个对象的final域前一定会先读
包含这个final域的对象引用。

### Q8:谈一谈synchronized

每个Java对象都有- -个关联的monitor,使用synchronized时JVM会根据使用环境找到对象的
monitor,根据monitor的状态进行加解锁的判断。如果成功加锁就成为该monitor的唯一持有者,
monitor在被释放前不能再被其他线程获取。
同步代码块使用monitorenter和monitorexit这两个字节码指令获取和释放monitor。这两个字节码
指令都需要一个引用类型的参数指明要锁定和解锁的对象，对于同步普通方法，锁是当前实例对象;对
于静态同步方法，锁是当前类的Class对象;对于同步方法块，锁是synchronized括号里的对象。
执行monitorenter指令时，首先尝试获取对象锁。如果这个对象没有被锁定，或当前线程已经持有
锁，就把锁的计数器加1,执行monitorexit 指令时会将锁计数器减1。一旦计数器为0锁随即就被释
放。
例如有两个线程A、B竞争monitor,当A竞争到锁时会将monitor中的owner设置为A,把B阻塞
并放到等待资源的ContentionList队列。ContentionList 中的部分线程会进入EntryList, EntryList 中
的线程会被指定为OnDeck竞争候选者，如果获得了锁资源将进入Owner状态，释放锁后进入
!Owner状态。被阻塞的线程会进入WaitSet。
被synchronized修饰的同步块对一条线程来说是可重入的，并且同步块在持有锁的线程释放锁前会阻
塞其他线程进入。从执行成本的角度看，持有锁是-个重量级的操作。Java线程是映射到操作系统的内
核线程.上的，如果要阻塞或唤醒一条线程， 需要操作系统帮忙完成，不可避免用户态到核心态的转换。
不公平的原因
所有收到锁请求的线程首先自旋，如果通过自旋也没有获取锁将被放入ContentionList,该做法对于已
经进入队列的线程不公平。
为了防止ContentionList尾部的元素被大量线程进行CAS访问影响性能，Owner 线程会在释放锁时将
ContentionList的部分线程移动到EntryList 并指定某个线程为OnDeck线程，该行为叫做竞争切换,
牺牲了公平性但提高了性能。



### Q9:锁优化有哪些策略?

JDK 6对synchronized做了很多优化，引入了自适应自旋、锁消除、锁粗化、偏向锁和轻量级锁等提
高锁的效率，锁-共有4个状态，级别从低到高依次是:无锁、偏向锁、轻量级锁和重量级锁，状态会
随竞争情况升级。锁可以升级但不能降级，这种只能升级不能降级的锁策略是为了提高锁获得和释放的
效率。

### Q10:自旋锁是什么?

同步对性能最大的影响是阻塞，挂起和恢复线程的操作都需要转入内核态完成。许多应用上共享数据的
锁定只会持续很短的时间，为了这段时间去挂起和恢复线程并不值得。如果机器有多个处理器核心，我
们可以让后面请求锁的线程稍等一会， 但不放弃处理器的执行时间，看看持有锁的线程是否很快会释放
锁。为了让线程等待只需让线程执行一个忙循环，这项技术就是自旋锁。
自旋锁在JDK1.4就已引入，默认关闭，在JDK6中改为默认开启。自旋不能代替阻塞，虽然避免了线程
切换开销，但要占用处理器时间，如果锁被占用的时间很短，自旋的效果就会非常好，反之只会白白消
耗处理器资源。如果自旋超过了限定的次数仍然没有成功获得锁，就应挂起线程，自旋默认限定次数是
10。

### Q11:什么是自适应自旋?

JDK6对自旋锁进行了优化，自旋时间不再固定，而是由前一次的自旋时间及锁拥有者的状态决定。
如果在同一个锁上，自旋刚刚成功获得过锁且持有锁的线程正在运行，虚拟机会认为这次自旋也很可能
成功，进而允许自旋持续更久。如果自旋很少成功，以后获取锁时将可能直接省略掉自旋，避免浪费处
理器资源。
有了自适应自旋，随着程序运行时间的增长，虚拟机对程序锁的状况预测就会越来越精准。

### Q12:锁消除是什么?

锁消除指即时编译器对检测到不可能存在共享数据竞争的锁进行消除。
主要判定依据来源于逃逸分析,如果判断一段代码中堆上的所有数据都只被一个线程访问，就可以当作
栈上的数据对待，认为它们是线程私有的而无须同步。

### Q13:锁粗化是什么?

原则需要将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中进行同步，这是为了使等待
锁的线程尽快拿到锁。
但如果-系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之外的，即使
没有线程竞争也会导致不必要的性能消耗。因此如果虚拟机探测到有--串零碎的操作都对同一个对象加
锁，将会把同步的范围扩展到整个操作序列的外部。

### Q14:偏向锁是什么?

偏向锁是为了在没有竞争的情况下减少锁开销，锁会偏向于第一个获得它的线程，如果在执行过程中锁
-直没有被其他线程获取，则持有偏向锁的线程将不需要进行同步。
当锁对象第一-次被线程获取时，虚拟机会将对象头中的偏向模式设为1,同时使用CAS把获取到锁的线
程ID记录在对象的Mark Word中。如果CAS成功，持有偏向锁的线程以后每次进入锁相关的同步块
都不再进行任何同步操作。
-旦有其他线程尝试获取锁，偏向模式立即结束，根据锁对象是否处于锁定状态决定是否撤销偏向，后
续同步按照轻量级锁那样执行。

### Q15:轻量级锁是什么?

轻量级锁是为了在没有竞争的前提下减少重量级锁使用操作系统互斥量产生的性能消耗。
在代码即将进入同步块时，如果同步对象没有被锁定，虚拟机将在当前线程的栈帧中建立一个锁记录空
间，存储锁对象目前Mark Word的拷贝。然后虚拟机使用CAS尝试把对象的Mark Word更新为指向
锁记录的指针，如果更新成功即代表该线程拥有了锁，锁标志位将转变为00,表示处于轻量级锁定状
态
如果更新失败就意味着至少存在一条线程与当前线程竞争。虚拟机检查对象的Mark Word是否指向当
前线程的栈帧，如果是则说明当前线程已经拥有了锁，直接进入同步块继续执行，否则说明锁对象已经
被其他线程抢占。如果出现两条以上线程争用同一个锁，轻量级锁就不再有效，将膨胀为重量级锁，锁
标志状态变为10，此时Mark Word存储的就是指向重量级锁的指针，后面等待锁的线程也必须阻塞。
解锁同样通过CAS进行，如果对象Mark Word仍然指向线程的锁记录，就用CAS把对象当前的Mark
Word和线程复制的Mark Word替换回来。假如替换成功同步过程就顺利完成了，如果失败则说明有
其他线程尝试过获取该锁，就要在释放锁的同时唤醒被挂起的线程。

### Q16:偏向锁、轻量级锁和重量级锁的区别?

偏向锁的优点是加解锁不需要额外消耗，和执行非同步方法比仅存在纳秒级差距，缺点是如果存在锁竞
争会带来额外锁撤销的消耗，适用只有一个线程访问同步代码块的场景。
轻量级锁的优点是竞争线程不阻塞，程序响应速度快，缺点是如果线程始终得不到锁会自旋消耗CPU,
适用追求响应时间、同步代码块执行快的场景。
重量级锁的优点是线程竞争不使用自旋不消耗CPU,缺点是线程会阻塞，响应时间慢，适应追求吞吐
量、同步代码块执行慢的场景。

### Q17: Lock和synchronized有什么区别?

Lock接是juc包的顶层接口，基于Lock接口，用户能够以非块结构来实现互斥同步,摆脱了语言特性
束缚，在类库层面实现同步。Lock并未用到synchronized,而是利用了voltile 的可见性。
重入锁ReentrantLock是Lock最常见的实现，与synchronized -样可重入，不过它增加了一些高级
功能:
●等待可中断:持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待而处理其他事
●公平锁:公平锁指多个线程在等待同-一个锁时，必须按照申请锁的顺序来依次获得锁，而非公平
锁不保证这一点， 在锁被释放时，任何线程都有机会获得锁。synchronized 是非公平的,
ReentrantLock在默认情况下是非公平的，可以通过构造方法指定公平锁。-旦使用了公平锁，性
能会急剧下降,影响吞吐量。
●锁绑定多个条件: -个ReentrantLock可以同时绑定多个Condition。 synchronized中锁对象的
wait跟notify 可以实现一个隐含条件,如果要和多个条件关联就不得不额外添加锁，而
ReentrantLock可以多次调用newCondition 创建多个条件。
一般优先考 虑使用synchronized:①synchronized是语法层面的同步，足够简单。②Lock必须确保
在finally中释放锁，否则一旦抛出异常有可能永远不会释放锁。使用synchronized可以由JVM来确保
即使出现异常锁也能正常释放。③尽管JDK5时ReentrantLock的性能优于synchronized,但在JDK6
进行锁优化后二者的性能基本持平。从长远来看JVM更容易针对synchronized优化，因为JVM可以在
线程和对象的元数据中记录synchronized中锁的相关信息，而使用Lock的话JVM很难得知具体哪些
锁对象是由特定线程持有的。

### Q18: ReentrantLock的可重入是怎么实现的?

以非公平锁为例，通过nonfai rTryAcquire方法获取锁，该方法增加了再次获取同步状态的处理逻
辑:判断当前线程是否为获取锁的线程来决定获取是否成功，如果是获取锁的线程再次请求则将同步状
态值增加并返回true,表示获取同步状态成功。
成功获取锁的线程再次获取锁将增加同步状态值，释放同步状态时将减少同步状态值。如果锁被获取了
n次，那么前n-1次tryRelease方法必须都返回fasle, 只有同步状态完全释放才能返回true, 该访
法将同步状态是否为0作为最终释放条件，释放时将占有线程设置为null并返回true。
对于非公平锁只要CAS设置同步状态成功则表示当前线程获取了锁，而公平锁则不同。公平锁使用
tryAcquire方法，该访法与nonfai rTryAcqui re的唯-区别就是判断条件中多了对同步队列中当
前节点是否有前驱节点的判断，如果该方法返回true表示有线程比当前线程更早请求锁，因此需要等
待前驱线程获取并释放锁后才能获取锁。



### Q19:什么是读写锁?

ReentrantLock是排他锁，同一时刻只允许一个线程访问，读写锁在同一时刻允许多个读线程访问，在
写线程访问时，所有的读写线程均阻塞。读写锁维护了一个读锁和一个写锁，通过分离读写锁使并发性
相比排他锁有了很大提升。
读写锁依赖AQS来实现同步功能，读写状态就是其同步器的同步状态。读写锁的自定义同步器需要在
同步状态，即一个int变量上维护多个读线程和一个写线程的状态。读写锁将变量切分成了两个部分,
高16位表示读，低16位表示写。
写锁是可重入排他锁，如果当前线程已经获得了写锁则增加写状态，如果当前线程在获取写锁时，读锁
已经被获取或者该线程不是已经获得写锁的线程则进入等待。写锁的释放与ReentrantLock的释放类
似，每次释放减少写状态，当写状态为0时表示写锁已被释放。
读锁是可重入共享锁，能够被多个线程同时获取，在没有其他写线程访问时，读锁总会被成功获取。如
果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取则进
入等待。读锁每次释放会减少读状态，减少的值是(1<<16) ，读锁的释放是线程安全的。
锁降级指把持住当前拥有的写锁，再获取读锁，随后释放先前拥有的写锁。
锁降级中读锁的获取是必要的，这是为了保证数据可见性，如果当前线程不获取读锁而直接释放写锁,
假设此刻另一个线程A获取写锁修改了数据，当前线程无法感知线程A的数据更新。如果当前线程获取
读锁，遵循锁降级的步骤，A将被阻塞，直到当前线程使用数据并释放读锁之后，线程A才能获取写锁
进行数据更新。

### Q20: AQS了解吗?

AQS队列同步器是用来构建锁或其他同步组件的基础框架，它使用一个volatile int state变量作为共享
资源，如果线程获取资源失败，则进入同步队列等待;如果获取成功就执行临界区代码，释放资源时会
通知同步队列中的等待线程。
同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，对同步状态
进行更改需要使用同步器提供的3个方法getstate、setstate 和compareAndSetstate ，它们保
证状态改变是安全的。子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步
接口，它仅仅定义若干同步状态获取和释放的方法，同步器既支持独占式也支持共享式。
同步器是实现锁的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。锁面向使用者，定义了
使用者与锁交互的接口，隐藏实现细节;同步器面向锁的实现者，简化了锁的实现方式，屏蔽了同步状
态管理、线程排队、等待与唤醒等底层操作。
每当有新线程请求资源时都会进入一个等待队列，只有当持有锁的线程释放锁资源后该线程才能持有资
源。等待队列通过双向链表实现，线程被封装在链表的Node节点中，Node 的等待状态包括:
CANCELLED (线程已取消)、 SIGNAL (线程需要唤醒)、CONDITION (线程 正在等待)、
PROPAGATE (后继节点会传播唤醒操作，只在共享模式下起作用)。



### Q21: AQS有哪两种模式?

独占模式表示锁只会被一个线程占用，其他线程必须等到持有锁的线程释放锁后才能获取锁，同一时间
只能有-个线程获取到锁。
共享模式表示多个线程获取同一个锁有可能成功，ReadLock 就采用共享模式。
独占模式通过acquire和release方法获取和释放锁，共享模式通过acquireShared和releaseShared
方法获取和释放锁。

### Q22: AQS独占式获取/释放锁的原理?

获取同步状态时，调用acquire方法，维护一个同步队列，使用tryAcquire方法安全地获取线程
同步状态，获取失败的线程会被构造同步节点并通过addwaiter 方法加入到同步队列的尾部，在队列
中自旋。之后调用acqui reQueued方法使得该节点以死循环的方式获取同步状态，如果获取不到则阻
塞,被阻塞线程的唤醒主要依靠前驱节点的出队或被中断实现，移出队列或停止自旋的条件是前驱节点
是头结点且成功获取了同步状态。
释放同步状态时，同步器调用tryRelease 方法释放同步状态，然后调用unparksuccessor 方法唤
醒头节点的后继节点，使后继节点重新尝试获取同步状态。



### Q23:为什么只有前驱节点是头节点时才能尝试获取同步

状态?
头节点是成功获取到同步状态的节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节
点。
目的是维护同步队列的FIFO原则，节点和节点在循环检查的过程中基本不通信，而是简单判断自己的
前驱是否为头节点，这样就使节点的释放规则符合FIFO,并且也便于对过早通知的处理，过早通知指前
驱节点不是头节点的线程由于中断被唤醒。



### Q24: AQS共享式式获取/释放锁的原理?

获取同步状态时，调用acqui reshared方法，该访法调用tryAcqui reShared方法尝试获取同步状
态，返回值为int类型，返回值不小于于0表示能获取同步状态。因此在共享式获取锁的自旋过程中，
成功获取同步状态并退出自旋的条件就是该方法的返回值不小于0。
释放同步状态时，调用releaseshared 方法，释放后会唤醒后续处于等待状态的节点。它和独占式的
区别在于tryReleaseshared 方法必须确保同步状态安全释放，通过循环CAS保证，因为释放同步状
态的操作会同时来自多个线程。



### Q25:线程的生命周期有哪些状态?

NEW:新建状态，线程被创建且未启动，此时还未调用start 方法。
RUNNABLE: Java 将操作系统中的就绪和运行两种状态统称为RUNNABLE,此时线程有可能在等待时
间片，也有可能在执行。
BLOCKED:阻塞状态，可能由于锁被其他线程占用、调用了sleep或join方法、执行了wait方法
等。
WAITING:等待状态，该状态线程不会被分配CPU时间片，需要其他线程通知或中断。可能由于调用
了无参的wait和join方法。
TIME_ _WAITING:限期等待状态，可以在指定时间内自行返回。导可能由于调用了带参的wait和
join方法。
TERMINATED:终止状态，表示当前线程已执行完毕或异常退出。



### Q26:线程的创建方式有哪些?

①继承Thread类并重写run方法。实现简单，但不符合里氏替换原则，不可以继承其他类。
②实现Runnable接口并重写run方法。避免了单继承局限性，编程更加灵活，实现解耦。
③实现Callable接口并重写call 方法。可以获取线程执行结果的返回值，并且可以抛出异常。



### Q27:线程有哪些方法?

①s1eep 方***导致当前线程进入休眠状态，与wait不同的是该方法不会释放锁资源，进入的是
TIMED-WAITING状态。
②yiled方法使当前线程让出CPU时间片给优先级相同或更高的线程，回到RUNNABLE状态，与其
他线程-起重新竞争CPU时间片。
③join方法用于等待其他线程运行终止，如果当前线程调用了另一个线程的join方法，则当前线程
进入阻塞状态，当另一个线程结束时当前线程才能从阻塞状态转为就绪态，等待获取CPU时间片。底层
使用的是wait，也会释放锁。

### Q28:什么是守护线程?

守护线程是一种支持型线程，可以通过setDaemon(true)将线程设置为守护线程，但必须在线程启动
前设置。
守护线程被用于完成支持性工作，但在JVM退出时守护线程中的finally块不- -定执行，因为JVM中没
有非守护线程时需要立即退出，所有守护线程都将立即终止，不能靠在守护线程使用finally确保关闭资
源。

### Q29:线程通信的方式有哪些?

命令式编程中线程的通信机制有两种，共享内存和消息传递。在共享内存的并发模型里线程间共享程序
的公共状态，通过写读内存中的公共状态进行隐式通信。在消息传递的并发模型里线程间没有公共状
态，必须通过发送消息来显式通信。Java并发采用共享内存模型，线程之间的通信总是隐式进行，整个
通信过程对程序员完全透明。
volatile告知程序任何对变量的读需要从主内存中获取，写必须同步刷新回主内存，保证所有线程对变
量访问的可见性。
synchronized确保多个线程在同- -时刻只能有一个处于方法或同步块中，保证线程对变量访问的原子
性、可见性和有序性。
等待通知机制指一个线程A调用了对象的wait方法进入等待状态，另- -线程B调用了对象的
notify/notifyA11方法，线程A收到通知后结束阻塞并执行后序操作。对象上的wait和
noti fy/notifyAl1如同开关信号，完成等待方和通知方的交互。
如果-一个线程执行了某个线程的join方法，这个线程就会阻塞等待执行了join 方法的线程终止,
这里涉及等待/通知机制。join 底层通过wait实现，线程终止时会调用自身的notifyA1]方法,
通知所有等待在该线程对象上的线程。
管道l0流用于线程间数据传输，媒介为内存。PipedOutputStream 和PipedWriter是输出流，相当于
生产者，PipedInputStream 和PipedReader是输入流，相当于消费者。管道流使用一个默认大小为
1KB的循环缓冲数组。输入流从缓冲数组读数据，输出流往缓冲数组中写数据。当数组已满时，输出流
所在线程阻塞;当数组首次为空时，输入流所在线程阻塞。
ThreadLocal是线程共享变量，但它可以为每个线程创建单独的副本，副本值是线程私有的，互相之间
不影响。

### Q30:线程池有什么好处?

降低资源消耗，复用已创建的线程，降低开销、控制最大并发数。
隔离线程环境，可以配置独立线程池，将较慢的线程与较快的隔离开，避免相互影响。
实现任务线程队列缓冲策略和拒绝机制。
实现某些与时间相关的功能，如定时执行、周期执行等。

### Q31:线程池处理任务的流程?

①核心线程池未满，创建一个新的线程执行任务，此时workCount < corePoolSize。
②如果核心线程池已满，工作队列未满，将线程存储在工作队列，此时workCount >= corePoolSize。
③如果工作队列已满，线程数小于最大线程数就创建一个新线程处理任务，此时workCount <
maximumPoolSize，这一步也需要获取全局锁。
④如果超过大小线程数，按照拒绝策略来处理任务，此时workCount > maximumPoolSize。
线程池创建线程时，会将线程封装成工作线程Worker, Worker 在执行完任务后还会循环获取工作队列
中的任务来执行。

### Q32:有哪些创建线程池的方法?

可以通过Executors的静态工厂方法创建线程池:
①newFixedThreadPool， 固定大小的线程池，核心线程数也是最大线程数，不存在空闲线程，keep
AliveTime= 0。该线程池使用的工作队列是无界阻塞队列LinkedBlockingQueue,适用于负载较重的
服务器。
②newsingleThreadExecutor, 使用单线程，相当于单线程串行执行所有任务，适用于需要保证顺
序执行任务的场景。
③newCachedThreadPoo1，maximumPoolSize 设置为Integer最大值，是高度可伸缩的线程池。该
线程池使用的工作队列是没有容量的SynchronousQueue,如果主线程提交任务的速度高于线程处理
的速度，线程池会不断创建新线程，极端情况下会创建过多线程而耗尽CPU和内存资源。适用于执行很
多短期异步任务的小程序或负载较轻的服务器。
④newscheduledThreadpool:线程数最大为Integer最大值，存在O0M风险。支持定期及周期性
任务执行，适用需要多个后台线程执行周期任务,同时需要限制线程数量的场景。相比Timer更安全,
功能更强，与newCachedThreadPoo1 的区别是不回收工作线程。
⑤newworkstealingPoo1 : JDK8 引入，创建持有足够线程的线程池支持给定的并行度，通过多个队
列减少竞争。



### Q33:创建线程池有哪些参数?

①corePoolSize:常驻核心线程数，如果为0，当执行完任务没有任何请求时会消耗线程池;如果大于
0，即使本地任务执行完，核心线程也不会被销毁。该值设置过大会浪费资源，过小会导致线程的频繁
创建与销毁。
②maximumPoolSize:线程池能够容纳同时执行的线程最大数，必须大于等于1，如果与核心线程数
设置相同代表固定大小线程池。
③keep AliveTime:线程空闲时间，线程空闲时间达到该值后会被销毁，直到只剩下corePoolSize个
线程为止，避免浪费内存资源。
④unit: keep AliveTime的时间单位。
⑤workQueue:工作队列，当线程请求数大于等于corePoolSize时线程会进入阻塞队列。
⑥threadFactory:线程工厂，用来生产- -组相同任务的线程。可以给线程命名，有利于分析错误。
⑦handler: 拒绝策略，默认使用AbortPolicy丢弃任务并抛出异常，CallerRunsPolicy表示重新尝试
提交该任务，DiscardOldestPolicy 表示抛弃队列里等待最久的任务并把当前任务加入队列，
DiscardPolicy表示直接抛弃当前任务但不抛出异常。



### Q34:如何关闭线程池?

可以调用shutdown 或shutdownNow方法关闭线程池，原理是遍历线程池中的工作线程，然后逐个
调用线程的interrupt方法中断线程，无法响应中断的任务可能永远无法终止。
区别是shutdownNow 首先将线程池的状态设为STOP,然后尝试停止正在执行或暂停任务的线程，并
返回等待执行任务的列表。而shutdown只是将线程池的状态设为SHUTDOWN,然后中断没有正在
执行任务的线程。
通常调用shutdown来关闭线程池，如果任务不一定要 执行完可调用shutdownNow



### Q35:线程池的选择策略有什么?

可以从以下角度分析:①任务性质: CPU密集型、I0 密集型和混合型。②任务优先级。③任务执行时
间。④任务依赖性:是否依赖其他资源，如数据库连接。
性质不同的任务可用不同规模的线程池处理，CPU 密集型任务应配置尽可能小的线程，如配置Nepu+1
个线程的线程池。由于10密集型任务线程并不是一直在执行任务， 应配置尽可能多的线程，如
2*Nepu。混合型的任务,如果可以拆分，将其拆分为一个CPU密集型任务和一个I0密集型任务，只
要两个任务执行的时间相差不大那么分解后的吞吐量将高于串行执行的吞吐量，如果相差太大则没必要
分解。
优先级不同的任务可以使用优先级队列PriorityBlockingQueue处理。
执行时间不同的任务可以交给不同规模的线程池处理，或者使用优先级队列让执行时间短的任务先执
行。
依赖数据库连接池的任务，由于线程提交SQL后需要等待数据库返回的结果，等待的时间越长CPU空
闲的时间就越长，因此线程数应该尽可能地设置大-些，提高CPU的利用率。
建议使用有界队列，能增加系统的稳定性和预警能力，可以根据需要设置的稍微大- -些。



### Q36:阻塞队列有哪些选择?

阻塞队列支持阻塞插入和移除，当队列满时，阻塞插入元素的线程直到队列不满。当队列为空时，获取
元素的线程会被阻塞直到队列非空。阻塞队列常用于生产者和消费者的场景，阻塞队列就是生产者用来
存放元素，消费者用来获取元素的容器。
Java中的阻塞队列
ArrayBlockingQueue,由数组组成的有界阻塞队列，默认情况下不保证线程公平,有可能先阻塞的线
程最后才访问队列。
LinkedBlockingQueue,由链表结构组成的有界阻塞队列，队列的默认和最大长度为Integer 最大值。
PriorityBlockingQueue, 支持优先级的无界阻塞队列，默认情况下元素按照升序排序。可自定义
compareTo方法指定排序规则，或者初始化时指定Comparator排序,不能保证同优先级元素的顺
序。
DelayQueue,支持延时获取元素的无界阻塞队列，使用优先级队列实现。创建元素时可以指定多久才
能从队列中获取当前元素，只有延迟期满时才能从队列中获取元素，适用于缓存和定时调度。
SynchronousQueue,不存储元素的阻塞队列，每一个put必须等待一个take。默认使用非公平策
略，也支持公平策略，适用于传递性场景，吞吐量高。
LinkedTransferQueue,链表组成的无界阻塞队列，相对于其他阻塞队列多了tryTransfer 和
transfer方法。transfer 方法:如果当前有消费者正等待接收元素，可以把生产者传入的元素立刻
传输给消费者，否则会将元素放在队列的尾节点并等到该元素被消费者消费才返回。tryTransfer 方
法用来试探生产者传入的元素能否直接传给消费者,如果没有消费者等待接收元素则返回false,和
transfer的区别是无论消费者是否消费都会立即返回。
LinkedBlockingDeque,链表组成的双向阻塞队列，可从队列的两端插入和移出元素，多线程同时入队
时减少了竞争。
实现原理
使用通知模式实现，生产者往满的队列里添加元素时会阻塞，当消费者消费后， 会通知生产者当前队列
可用。当往队列里插入-个元素，如果队列不可用，阻塞生产者主要通过LockSupport的park 方法
实现，不同操作系统中实现方式不同，在Linux下使用的是系统方法pthread. cond _wait实现。



### Q37:谈一谈ThreadLocal

ThreadLoacl是线程共享变量,主要用于-一个线程内跨类、方法传递数据。ThreadLoadl 有-个静态内
部类ThreadLocalMap,其Key是ThreadLocal对象，值是Entry 对象，Entry 中只有一一个Object类
的vaule值。ThreadLocal是线程共享的，但ThreadLocalMap是每个线程私有的。ThreadLocal 主要
有set、get 和remove三个方法。
set方法
首先获取当前线程，然后再获取当前线程对应的ThreadLocalMap类型的对象map。如果map存在就
直接设置值，key 是当前的ThreadLocal对象，value 是传入的参数。
如果map不存在就通过createMap 方法为当前线程创建-个ThreadLocalMap对象再设置值。
get方法
首先获取当前线程，然后再获取当前线程对应的ThreadLocalMap类型的对象map。如果map存在就
以当前ThreadLocal对象作为key获取Entry类型的对象e，如果e存在就返回它的value属性。
如果e不存在或者map不存在，就调用setInitialvalue 方法先为当前线程创建一个
ThreadLocalMap对象然后返回默认的初始值null。
remove方法
首先通过当前线程获取其对应的ThreadLocalMap类型的对象m,如果m不为空,就解除
ThreadLocal这个key及其对应的value值的联系。
存在的问题
线程复用会产生脏数据，由于线程池会重用Thread对象，因此与Thread绑定的ThreadLocal也会被
重用。如果没有调用remove清理与线程相关的ThreadLocal信息，那么假如下一一个线程没有调用set
设置初始值就可能get到重用的线程信息。
ThreadLocal还存在内存泄漏的问题，由于ThreadLocal是弱引用，但Entry的value是强引用，因此
当Threadl ocal被垃圾回收后，value 依旧不会被释放。因此需要及时调用remove方法进行清理操
作。
